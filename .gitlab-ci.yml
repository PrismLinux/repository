image: archlinux:base-devel

variables:
  REPO_NAME: "prismlinux"
  REPO_DIR: "public"
  CACHE_DIR: "cache"
  CHECKSUMS_FILE: "package_checksums.txt"
  REBUILD_TRIGGER_FILE: "rebuild_packages.txt"
  DYNAMIC_PIPELINE_FILE: "dynamic_pipeline.yml"
  CURL_TIMEOUT: "30"
  CURL_CONNECT_TIMEOUT: "10"

cache:
  key: "repo-cache-${CI_COMMIT_REF_SLUG}"
  paths:
    - "${CACHE_DIR}/"
    - "${CHECKSUMS_FILE}"
    - "${REBUILD_TRIGGER_FILE}"
    - "/var/cache/pacman/pkg/"
  policy: pull-push

stages:
  - prepare
  - check
  - build
  - test
  - generate
  - deploy

.install_dependencies: &install_dependencies
  - pacman -Syu --noconfirm --needed curl jq base-devel git unzip
  - pacman-key --init || true
  - pacman-key --populate archlinux || true

.error_handling: &error_handling
  - set -euo pipefail
  - |
    trap 'echo "Error at line $LINENO. Exit code: $?" >&2' ERR

.gitlab_api_config: &gitlab_api_config
  - |
    if [ -z "${GITLAB_TOKEN:-}" ]; then
      echo "ERROR: GITLAB_TOKEN is not set"
      exit 1
    fi
    export CURL_OPTS="--silent --show-error --fail --connect-timeout ${CURL_CONNECT_TIMEOUT} --max-time ${CURL_TIMEOUT}"

validate_config:
  stage: prepare
  before_script:
    - *install_dependencies
  script:
    - *error_handling
    - |
      if [ ! -f packages_id.txt ]; then
        echo "ERROR: packages_id.txt not found!"
        exit 1
      fi
      if ! grep -vE '^\s*#|^\s*$' packages_id.txt | tr -d '\r' | grep -qE '^[0-9]+'; then
        echo "ERROR: packages_id.txt contains invalid project IDs"
        exit 1
      fi
      echo "Configuration validation passed"

check_packages:
  stage: check
  needs: ["validate_config"]
  before_script:
    - *install_dependencies
    - *gitlab_api_config
  script:
    - *error_handling
    - mkdir -p "${CACHE_DIR}"
    - |
      declare -A old_checksums new_checksums remote_packages_map
      if [ -f "${CHECKSUMS_FILE}" ]; then
        while IFS='|' read -r filename checksum; do
          [ -n "$filename" ] && [ -n "$checksum" ] && old_checksums["$filename"]="$checksum"
        done < "${CHECKSUMS_FILE}"
      fi

      get_project_packages() {
        local project_id="$1"
        local releases_api_url="https://gitlab.com/api/v4/projects/${project_id}/releases"
        local latest_release
        latest_release=$(curl ${CURL_OPTS} --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$releases_api_url" | jq -r '.[0]? // empty')
        if [ -z "$latest_release" ] || [ "$latest_release" = "null" ]; then
          echo "WARNING: No releases found for project ${project_id}"
          return 1
        fi
        while IFS= read -r asset; do
          [ -z "$asset" ] && continue
          local asset_url asset_name
          asset_url=$(echo "$asset" | jq -r '.url // empty')
          asset_name=$(echo "$asset" | jq -r '.name // empty')
          if [[ "$asset_name" == *.pkg.tar.zst ]] && [ -n "$asset_url" ]; then
            remote_packages_map["${asset_name}"]="${asset_url}"
          fi
        done <<< "$(echo "$latest_release" | jq -c '.assets.links[]? // empty')"
      }

      download_and_check() {
        local pkg_filename="$1" download_url="$2" temp_file
        temp_file=$(mktemp)
        if curl --location ${CURL_OPTS} --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "$temp_file" "$download_url"; then
          sha256sum "$temp_file" | awk '{print $1}'
          rm "$temp_file"
          return 0
        fi
        echo "ERROR: Failed to download ${pkg_filename}" >&2
        rm -f "$temp_file"
        return 1
      }

      project_ids=$(grep -vE '^\s*#|^\s*$' packages_id.txt | awk '{print $1}' | tr -d '\r')
      for project_id in $project_ids; do get_project_packages "$project_id" || continue; done

      changed_packages=()
      for pkg_filename in "${!remote_packages_map[@]}"; do
        download_url="${remote_packages_map[$pkg_filename]}"
        if checksum=$(download_and_check "$pkg_filename" "$download_url"); then
          new_checksums["$pkg_filename"]="$checksum"
          if [[ ! -v old_checksums["$pkg_filename"] ]] || [[ "${old_checksums[$pkg_filename]}" != "$checksum" ]]; then
            changed_packages+=("$pkg_filename")
            echo "CHANGED: $pkg_filename"
          fi
        fi
      done

      if [ ${#changed_packages[@]} -gt 0 ]; then
        printf '%s\n' "${changed_packages[@]}" > "${REBUILD_TRIGGER_FILE}"
        temp_checksums=$(mktemp)
        for pkg_filename in "${!new_checksums[@]}"; do
          echo "${pkg_filename}|${new_checksums[$pkg_filename]}" >> "$temp_checksums"
        done
        mv "$temp_checksums" "${CHECKSUMS_FILE}"
      else
        echo "No package changes detected."
        rm -f "${REBUILD_TRIGGER_FILE}"
      fi
  artifacts:
    paths:
      - "${REBUILD_TRIGGER_FILE}"
      - "${CHECKSUMS_FILE}"
    expire_in: 1 hour
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule'
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

build_repository:
  stage: build
  needs: ["check_packages"]
  before_script:
    - *install_dependencies
    - *gitlab_api_config
  script:
    - *error_handling
    - |
      REPO_ARCH_DIR="${REPO_DIR}/x86_64"
      mkdir -p "${REPO_ARCH_DIR}"
      project_ids=$(grep -vE '^\s*#|^\s*$' packages_id.txt | awk '{print $1}' | tr -d '\r')
      package_count=0

      for project_id in $project_ids; do
        releases_api_url="https://gitlab.com/api/v4/projects/${project_id}/releases"
        latest_release=$(curl ${CURL_OPTS} --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$releases_api_url" | jq -r '.[0]? // empty')
        if [ -z "$latest_release" ] || [ "$latest_release" = "null" ]; then
          echo "WARNING: No releases found for project ${project_id}"
          continue
        fi
        echo "$latest_release" | jq -c '.assets.links[]? | select(.name | endswith(".pkg.tar.zst"))' | while read -r asset; do
          asset_url=$(echo "$asset" | jq -r '.url')
          asset_name=$(echo "$asset" | jq -r '.name')
          if [ -n "$asset_url" ] && [ -n "$asset_name" ]; then
            echo "Downloading ${asset_name}..."
            curl --location ${CURL_OPTS} --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "${REPO_ARCH_DIR}/${asset_name}" "${asset_url}"
            ((package_count++))
          fi
        done
      done

      cd "${REPO_ARCH_DIR}"
      rm -f ${REPO_NAME}.db* ${REPO_NAME}.files*
      if [ $package_count -gt 0 ]; then
        repo-add --nocolor --nosign --verify "${REPO_NAME}.db.tar.gz" *.pkg.tar.zst
        ln -sf "${REPO_NAME}.db.tar.gz" "${REPO_NAME}.db"
        ln -sf "${REPO_NAME}.files.tar.gz" "${REPO_NAME}.files"
        echo "packages_found=true" > ../../package_status.txt
      else
        tar -czf "${REPO_NAME}.db.tar.gz" -T /dev/null
        tar -czf "${REPO_NAME}.files.tar.gz" -T /dev/null
        ln -sf "${REPO_NAME}.db.tar.gz" "${REPO_NAME}.db"
        ln -sf "${REPO_NAME}.files.tar.gz" "${REPO_NAME}.files"
        echo "packages_found=false" > ../../package_status.txt
      fi
  artifacts:
    paths:
      - "${REPO_DIR}/"
      - package_status.txt
    expire_in: 1 day
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $REBUILD_TRIGGER_FILE
      exists:
        - "${REBUILD_TRIGGER_FILE}"

test_packages:
  stage: test
  needs: ["build_repository"]
  before_script:
    - *install_dependencies
  script:
    - *error_handling
    - |
      REPO_ARCH_DIR="${REPO_DIR}/x86_64"
      if [ ! -f "${REPO_ARCH_DIR}/${REPO_NAME}.db" ]; then
        echo "ERROR: Repository database not found!"
        exit 1
      fi
      if ! ls "${REPO_ARCH_DIR}"/*.pkg.tar.zst 1> /dev/null 2>&1; then
        echo "No packages found to test. Skipping."
        exit 0
      fi
      for pkg_file in "${REPO_ARCH_DIR}"/*.pkg.tar.zst; do
        if [ -f "$pkg_file" ]; then
          echo "Validating: $(basename "$pkg_file")"
          pacman -Qip "$pkg_file" >/dev/null 2>&1 || { echo "ERROR: Invalid package: $(basename "$pkg_file")"; exit 1; }
        fi
      done
      echo "Repository validation passed."
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $REBUILD_TRIGGER_FILE
      exists:
        - "${REBUILD_TRIGGER_FILE}"

generate_dynamic_pipeline:
  stage: generate
  needs: ["build_repository", "test_packages"]
  before_script:
    - *install_dependencies
  script:
    - *error_handling
    - |
      if grep -q "packages_found=true" package_status.txt; then
        cat > "${DYNAMIC_PIPELINE_FILE}" << 'EOF'
        pages:
          stage: deploy
          image: archlinux:base-devel
          script:
            - set -euo pipefail
            - trap 'echo "Error at line $LINENO. Exit code: $?" >&2' ERR
            - |
              REPO_ARCH_DIR="public/x86_64"
              API_DIR="public/api"
              mkdir -p "${API_DIR}"
              temp_json_objects=$(mktemp)

              echo "Generating package information JSON..."

              for pkg_file in "${REPO_ARCH_DIR}"/*.pkg.tar.zst; do
                [ -f "$pkg_file" ] || continue
                
                pkg_info=$(pacman -Qip "$pkg_file" 2>/dev/null || echo "")
                
                if [ -n "$pkg_info" ]; then
                  pkg_name=$(echo "$pkg_info"    | grep -oP '^Name\s+:\s+\K.*')
                  pkg_version=$(echo "$pkg_info" | grep -oP '^Version\s+:\s+\K.*')
                  pkg_desc=$(echo "$pkg_info"    | grep -oP '^Description\s+:\s+\K.*')
                  pkg_arch=$(echo "$pkg_info"    | grep -oP '^Architecture\s+:\s+\K.*')
                  pkg_size=$(echo "$pkg_info"    | grep -oP '^Installed Size\s+:\s+\K.*')
                  
                  jq -n --arg name "$pkg_name" \
                        --arg version "$pkg_version" \
                        --arg desc "$pkg_desc" \
                        --arg arch "$pkg_arch" \
                        --arg size "$pkg_size" \
                        --arg file "$(basename "$pkg_file")" \
                        '{name: $name, version: $version, description: $desc, architecture: $arch, installed_size: $size, filename: $file}' >> "$temp_json_objects"
                fi
              done

              jq -s . "$temp_json_objects" > "${API_DIR}/packages.json"
              rm "$temp_json_objects"

              echo "API file 'packages.json' created successfully."
              echo "GitLab Pages content is ready in the 'public' directory."
          artifacts:
            paths:
              - public
          rules:
            - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      EOF
      else
        echo "No packages found, skipping dynamic pipeline generation."
        touch "${DYNAMIC_PIPELINE_FILE}"
      fi
  artifacts:
    paths:
      - "${DYNAMIC_PIPELINE_FILE}"

trigger_pages_deploy:
  stage: deploy
  trigger:
    include:
      - artifact: "dynamic_pipeline.yml"
        job: generate_dynamic_pipeline
    strategy: depend
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      exists:
        - "${DYNAMIC_PIPELINE_FILE}"
