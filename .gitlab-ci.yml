image: archlinux:latest

variables:
  REPO_NAME: "prismlinux"
  REPO_DIR: "public"
  CACHE_DIR: "cache"
  CHECKSUMS_FILE: "package_checksums.txt"
  REBUILD_TRIGGER_FILE: "rebuild_packages.txt"

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule'
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == 'push'
    - if: ($CI_PIPELINE_SOURCE == 'push' || $CI_PIPELINE_SOURCE == 'merge_request_event')
      changes:
        - website/**/*
        - .gitlab-ci.yml
        - packages_id.txt

cache:
  key: "repo-cache-${CI_COMMIT_REF_SLUG}"
  paths:
    - "${CACHE_DIR}/"
    - "${CHECKSUMS_FILE}"
    - "${REBUILD_TRIGGER_FILE}"
  policy: pull-push

stages:
  - check
  - build
  - deploy
  - cleanup

check_packages:
  stage: check
  before_script:
  - pacman -Syu --noconfirm
  - pacman -S --noconfirm curl jq base-devel git unzip
  script: |
    set -eo pipefail
    
    echo "Checking for package updates..."
    mkdir -p "${CACHE_DIR}"
    
    declare -A old_checksums
    declare -A new_checksums
    declare -A remote_packages_map
    
    if [ -f "${CHECKSUMS_FILE}" ]; then
      while IFS='|' read -r filename checksum; do
        if [ -n "$filename" ] && [ -n "$checksum" ]; then
          old_checksums["$filename"]="$checksum"
        fi
      done < "${CHECKSUMS_FILE}"
    fi
    
    if [ ! -f packages_id.txt ]; then
      echo "ERROR: packages_id.txt not found!"
      exit 1
    fi
    
    PROJECT_IDS_TO_PROCESS=$(grep -vE '^\s*#|^\s*$' packages_id.txt | awk '{print $1}' | tr '\n' ' ')
    echo "Processing Project IDs: ${PROJECT_IDS_TO_PROCESS}"
    
    for project_id in $PROJECT_IDS_TO_PROCESS; do
      RELEASES_API_URL="https://gitlab.com/api/v4/projects/${project_id}/releases"
      LATEST_RELEASE=$(curl --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$RELEASES_API_URL" | jq -r '.[0]')
      
      if [ "$LATEST_RELEASE" = "null" ]; then
        echo "WARNING: No releases found for project ${project_id}. Skipping."
        continue
      fi
      
      while IFS= read -r asset; do
        if [ -z "$asset" ]; then continue; fi
        ASSET_URL=$(echo "$asset" | jq -r '.url')
        ASSET_NAME=$(echo "$asset" | jq -r '.name')
        
        if [[ "$ASSET_NAME" == *.pkg.tar.zst ]]; then
          remote_packages_map["${ASSET_NAME}"]="${ASSET_URL}"
        fi
      done <<< "$(echo "$LATEST_RELEASE" | jq -c '.assets.links[]?')"
    done
    
    download_and_check() {
      local pkg_filename="$1"
      local download_url="$2"
      local temp_file=$(mktemp)
      
      if curl --location --silent --show-error --fail --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "$temp_file" "$download_url"; then
        local checksum=$(sha256sum "$temp_file" | awk '{print $1}')
        echo "$checksum"
        rm "$temp_file"
      else
        echo "ERROR: Failed to download ${pkg_filename}" >&2
        rm -f "$temp_file"
        echo ""
      fi
    }
    
    echo "Checking checksums for remote packages..."
    changed_packages=()
    
    for pkg_filename in "${!remote_packages_map[@]}"; do
      download_url="${remote_packages_map[$pkg_filename]}"
      checksum=$(download_and_check "$pkg_filename" "$download_url")
      
      if [ -n "$checksum" ]; then
        new_checksums["$pkg_filename"]="$checksum"
        
        if [[ ! -v old_checksums["$pkg_filename"] ]] || [[ "${old_checksums[$pkg_filename]}" != "$checksum" ]]; then
          changed_packages+=("$pkg_filename")
          echo "CHANGED: $pkg_filename (new checksum: $checksum)"
        fi
      fi
    done
    
    if [ ${#changed_packages[@]} -gt 0 ]; then
      echo "Found ${#changed_packages[@]} changed packages"
      printf '%s\n' "${changed_packages[@]}" > "${REBUILD_TRIGGER_FILE}"
      
      > "${CHECKSUMS_FILE}"
      for pkg_filename in "${!new_checksums[@]}"; do
        checksum="${new_checksums[$pkg_filename]}"
        echo "${pkg_filename}|${checksum}" >> "${CHECKSUMS_FILE}"
      done
      
      echo "Triggering rebuild pipeline..."
      curl --request POST \
           --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
           --header "Content-Type: application/json" \
           --data '{"ref":"'$CI_DEFAULT_BRANCH'","variables":[{"key":"REBUILD_PACKAGES","value":"true"}]}' \
           "https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/pipeline"
    else
      echo "No package changes detected"
    fi
    
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule'
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == 'push'
      when: manual
  artifacts:
    paths:
      - "${REBUILD_TRIGGER_FILE}"
      - "${CHECKSUMS_FILE}"
    expire_in: 1 hour

build_packages:
  stage: build
  before_script:
    - pacman -Syu --noconfirm
    - pacman -S --noconfirm curl jq base-devel git unzip
  script: |
    set -eo pipefail
    REPO_ARCH_DIR="${REPO_DIR}/x86_64"
    
    echo "Ensuring required directories exist..."
    mkdir -p "${REPO_ARCH_DIR}"
    mkdir -p "${CACHE_DIR}"
    
    declare -A remote_packages_map
    declare -A packages_to_rebuild
    
    if [ -f "${REBUILD_TRIGGER_FILE}" ]; then
      while IFS= read -r pkg_filename; do
        if [ -n "$pkg_filename" ]; then
          packages_to_rebuild["$pkg_filename"]=1
        fi
      done < "${REBUILD_TRIGGER_FILE}"
    fi
    
    if [ ! -f packages_id.txt ]; then
      echo "ERROR: packages_id.txt not found!"
      exit 1
    fi
    
    PROJECT_IDS_TO_PROCESS=$(grep -vE '^\s*#|^\s*$' packages_id.txt | awk '{print $1}' | tr '\n' ' ')
    
    for project_id in $PROJECT_IDS_TO_PROCESS; do
      RELEASES_API_URL="https://gitlab.com/api/v4/projects/${project_id}/releases"
      LATEST_RELEASE=$(curl --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$RELEASES_API_URL" | jq -r '.[0]')
      
      if [ "$LATEST_RELEASE" = "null" ]; then
        continue
      fi
      
      while IFS= read -r asset; do
        if [ -z "$asset" ]; then continue; fi
        ASSET_URL=$(echo "$asset" | jq -r '.url')
        ASSET_NAME=$(echo "$asset" | jq -r '.name')
        
        if [[ "$ASSET_NAME" == *.pkg.tar.zst ]]; then
          remote_packages_map["${ASSET_NAME}"]="${ASSET_URL}"
        fi
      done <<< "$(echo "$LATEST_RELEASE" | jq -c '.assets.links[]?')"
    done
    
    echo "Processing packages (selective rebuild)..."
    
    for pkg_filename in "${!remote_packages_map[@]}"; do
      download_url="${remote_packages_map[$pkg_filename]}"
      cached_file="${CACHE_DIR}/${pkg_filename}"
      
      if [[ -v packages_to_rebuild["$pkg_filename"] ]]; then
        echo "  -> Rebuilding package: ${pkg_filename}"
        if curl --location --silent --show-error --fail --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "${REPO_ARCH_DIR}/${pkg_filename}" "$download_url"; then
          cp "${REPO_ARCH_DIR}/${pkg_filename}" "${CACHE_DIR}/${pkg_filename}"
        else
          echo "    ERROR: Failed to download ${pkg_filename}"
        fi
      elif [ -f "$cached_file" ]; then
        echo "  -> Using cached package: ${pkg_filename}"
        cp "$cached_file" "${REPO_ARCH_DIR}/${pkg_filename}"
      else
        echo "  -> Downloading missing package: ${pkg_filename}"
        if curl --location --silent --show-error --fail --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "${REPO_ARCH_DIR}/${pkg_filename}" "$download_url"; then
          cp "${REPO_ARCH_DIR}/${pkg_filename}" "${CACHE_DIR}/${pkg_filename}"
        else
          echo "    ERROR: Failed to download ${pkg_filename}"
        fi
      fi
    done
    
    echo "Cleaning up old cached packages..."
    for cached_file in "${CACHE_DIR}"/*.pkg.tar.zst; do
      [ -f "$cached_file" ] || continue
      cached_filename=$(basename "$cached_file")
      
      if [[ ! -v remote_packages_map["$cached_filename"] ]]; then
        echo "  -> Removing obsolete cached package: ${cached_filename}"
        rm "$cached_file"
      fi
    done
    
    echo "Updating repository database..."
    (
      cd "${REPO_ARCH_DIR}"
      
      rm -f ${REPO_NAME}.db ${REPO_NAME}.db.tar.gz ${REPO_NAME}.files ${REPO_NAME}.files.tar.gz
      
      if ls ./*.pkg.tar.zst 1> /dev/null 2>&1; then
        echo "Found packages. Rebuilding repository database..."
        repo-add "${REPO_NAME}.db.tar.gz" *.pkg.tar.zst
      else
        echo "No packages found in repository. The database will be empty."
        touch "${REPO_NAME}.db.tar.gz" "${REPO_NAME}.files.tar.gz"
      fi
      
      ln -sf "${REPO_NAME}.db.tar.gz" "${REPO_NAME}.db"
      ln -sf "${REPO_NAME}.files.tar.gz" "${REPO_NAME}.files"
    )
    
  rules:
    - if: $REBUILD_PACKAGES == "true"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == 'push'
      changes:
        - packages_id.txt
    - when: manual
  artifacts:
    paths:
      - "${REPO_DIR}/x86_64/"
    expire_in: 1 day

pages:
  stage: deploy
  pages: true
  dependencies:
    - build_packages
  before_script:
    - pacman -Syu --noconfirm
    - pacman -S --noconfirm curl jq base-devel git unzip
    - curl -fsSL https://bun.sh/install | bash
    - export PATH="$HOME/.bun/bin:$PATH"
  script: |
    set -eo pipefail
    REPO_ARCH_DIR="${REPO_DIR}/x86_64"
    
    echo "Ensuring required directories exist..."
    mkdir -p "${REPO_DIR}/api"
    
    echo "Cleaning up existing Vue app files in public/ (index.html, assets/)..."
    rm -f "${REPO_DIR}/index.html" || true
    rm -rf "${REPO_DIR}/assets" || true
    
    echo "Generating package metadata for web interface (packages.json)..."
    generate_json_objects() {
      for pkg_file in "${REPO_ARCH_DIR}"/*.pkg.tar.zst; do
        [ -f "$pkg_file" ] || continue
        pkg_info=$(pacman -Qip "$pkg_file" 2>/dev/null)
        
        jq -cn \
          --arg name "$(echo "$pkg_info" | grep -m1 "^Name" | sed 's/Name\s*:\s*//')" \
          --arg version "$(echo "$pkg_info" | grep -m1 "^Version" | sed 's/Version\s*:\s*//')" \
          --arg desc "$(echo "$pkg_info" | grep -m1 "^Description" | sed 's/Description\s*:\s*//')" \
          --arg arch "$(echo "$pkg_info" | grep -m1 "^Architecture" | sed 's/Architecture\s*:\s*//')" \
          --arg filename "$(basename "$pkg_file")" \
          --arg size "$(ls -lh "$pkg_file" | awk '{print $5}')" \
          --arg modified "$(date -r "$pkg_file" '+%Y-%m-%d %H:%M:%S')" \
          --arg depends "$(echo "$pkg_info" | grep -m1 "^Depends On" | sed 's/Depends On\s*:\s*//' || echo 'None')" \
          --arg groups "$(echo "$pkg_info" | grep -m1 "^Groups" | sed 's/Groups\s*:\s*//' || echo 'None')" \
          '{name: $name, version: $version, description: $desc, architecture: $arch, filename: $filename, size: $size, modified: $modified, depends: $depends, groups: $groups}'
      done
    }
    generate_json_objects | jq -s . > "${REPO_DIR}/api/packages.json"
    
    echo "Building Vue frontend with Bun..."
    (
      cd website
      bun install --frozen-lockfile
      bun run build
    )
    
    echo "Copying built Vue app from website/dist to public directory..."
    cp -r website/dist/. "${REPO_DIR}/"
    
    echo "-----------------------------------------"
    echo "Cache statistics:"
    echo "Cache directory size: $(du -sh ${CACHE_DIR} 2>/dev/null || echo '0')"
    echo "Number of cached packages: $(ls -1 ${CACHE_DIR}/*.pkg.tar.zst 2>/dev/null | wc -l || echo '0')"
    echo "Repository packages: $(ls -1 ${REPO_ARCH_DIR}/*.pkg.tar.zst 2>/dev/null | wc -l || echo '0')"
    echo "-----------------------------------------"
    echo "Final check before artifact upload:"
    ls -laR public
    echo "-----------------------------------------"
    
  rules:
    - if: $REBUILD_PACKAGES == "true"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == 'push'
  artifacts:
    paths:
      - public

cleanup_old_artifacts:
  stage: cleanup
  before_script:
  - pacman -Syu --noconfirm
  - pacman -S --noconfirm curl jq base-devel git unzip
  script: |
    set -eo pipefail
    
    echo "Cleaning up old artifacts (older than 7 days)..."
    
    CUTOFF_DATE=$(date -d '7 days ago' --iso-8601)
    
    JOBS=$(curl --silent --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
           "https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/jobs?per_page=100&scope[]=success" | \
           jq -r '.[] | select(.finished_at < "'$CUTOFF_DATE'") | .id')
    
    if [ -n "$JOBS" ]; then
      echo "Found jobs with old artifacts to clean up"
      for job_id in $JOBS; do
        echo "  -> Cleaning artifacts for job $job_id"
        curl --request DELETE \
             --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
             "https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/jobs/$job_id/artifacts" || true
      done
    else
      echo "No old artifacts to clean up"
    fi
    
    echo "Cleaning up old pipeline artifacts..."
    PIPELINES=$(curl --silent --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
                "https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/pipelines?per_page=50&status=success" | \
                jq -r '.[] | select(.finished_at < "'$CUTOFF_DATE'") | .id')
    
    if [ -n "$PIPELINES" ]; then
      echo "Found pipelines with old artifacts to clean up"
      for pipeline_id in $PIPELINES; do
        echo "  -> Cleaning artifacts for pipeline $pipeline_id"
        curl --request DELETE \
             --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
             "https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/pipelines/$pipeline_id/artifacts" || true
      done
    else
      echo "No old pipeline artifacts to clean up"
    fi
    
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule'
    - when: manual
  allow_failure: true
