#
# CI/CD Pipeline for an CrystalLinux Aggregator Repository
# This pipeline fetches, syncs, and publishes a unified pacman repository.
#
image: archlinux:latest

variables:
  REPO_NAME: "crystallinux"
  # The directory to be deployed to GitLab Pages MUST be named 'public'.
  REPO_DIR: "public"
  PACKAGE_PROJECT_IDS: "70724583"

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule'
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == 'push'

# --- Cache ---
# Caches the repository contents to avoid re-downloading packages that haven't changed.
cache:
  key: "repo-cache-${CI_COMMIT_REF_SLUG}"
  paths:
    - "${REPO_DIR}/"
  policy: pull-push

# --- The single, combined build and deploy job ---
pages:
  stage: deploy
  
  before_script:
    - pacman -Syu --noconfirm
    - pacman -S --noconfirm curl jq base-devel git
  
  script:
    # We use a single script block to ensure all variables exist in the same shell.
    - |
      set -eo pipefail # Exit on any error
      REPO_ARCH_DIR="${REPO_DIR}/x86_64"
      mkdir -p "${REPO_ARCH_DIR}"
      echo "Repository directory is ${REPO_ARCH_DIR}"
      echo "Initial contents from cache:"
      ls -R "${REPO_DIR}"

      # --- Step 1: Get a list of ALL expected remote packages from releases ---
      declare -A remote_packages_map # Use an associative array for efficient lookups
      echo "Fetching list of all available remote packages from releases..."
      
      for project_id in $PACKAGE_PROJECT_IDS; do
        echo "--> Checking project ID: ${project_id}"
        
        # Get the latest release
        RELEASES_API_URL="https://gitlab.com/api/v4/projects/${project_id}/releases"
        LATEST_RELEASE=$(curl --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$RELEASES_API_URL" | jq -r '.[0]')
        
        if [ "$LATEST_RELEASE" = "null" ]; then
          echo "WARNING: No releases found for project ${project_id}. Skipping."
          continue
        fi
        
        # Extract release tag and assets
        RELEASE_TAG=$(echo "$LATEST_RELEASE" | jq -r '.tag_name')
        echo "Found latest release: ${RELEASE_TAG}"
        
        # Get release assets (links)
        RELEASE_ASSETS=$(echo "$LATEST_RELEASE" | jq -r '.assets.links[]?')
        
        if [ -z "$RELEASE_ASSETS" ]; then
          echo "WARNING: No assets found in release ${RELEASE_TAG}. Skipping."
          continue
        fi
        
        # Process each asset link
        while IFS= read -r asset; do
          if [ -z "$asset" ]; then continue; fi
          
          ASSET_URL=$(echo "$asset" | jq -r '.url')
          ASSET_NAME=$(echo "$asset" | jq -r '.name')
          
          # Check if it's a package file
          if [[ "$ASSET_NAME" == *.pkg.tar.zst ]]; then
            echo "Found remote package: ${ASSET_NAME}"
            remote_packages_map["${ASSET_NAME}"]="${ASSET_URL}"
          fi
        done <<< "$(echo "$LATEST_RELEASE" | jq -c '.assets.links[]?')"
      done
      echo "Total unique remote packages found: ${#remote_packages_map[@]}"
      
      # --- Step 2: Sync local repository with remote list ---
      REPO_UPDATED=false
      
      # 2a: Remove orphaned packages
      echo "Checking for orphaned packages in local repository..."
      for local_pkg_path in "${REPO_ARCH_DIR}"/*.pkg.tar.zst; do
        [ -f "$local_pkg_path" ] || continue
        local_pkg_filename=$(basename "$local_pkg_path")
        if [[ ! -v remote_packages_map["${local_pkg_filename}"] ]]; then
          echo "  -> Removing orphaned package: ${local_pkg_filename}"
          rm "$local_pkg_path"
          REPO_UPDATED=true
        fi
      done
      
      # 2b: Download new or updated packages
      echo "Checking for new packages to download..."
      for pkg_filename in "${!remote_packages_map[@]}"; do
        if [ ! -f "${REPO_ARCH_DIR}/${pkg_filename}" ]; then
          echo "  -> Downloading new package: ${pkg_filename}"
          DOWNLOAD_URL="${remote_packages_map[$pkg_filename]}"
          
          # Download the package with proper error handling
          if curl --location --silent --show-error --fail --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "${REPO_ARCH_DIR}/${pkg_filename}" "${DOWNLOAD_URL}"; then
            echo "    Successfully downloaded: ${pkg_filename}"
            REPO_UPDATED=true
          else
            echo "    ERROR: Failed to download ${pkg_filename} from ${DOWNLOAD_URL}"
            # Remove partial file if it exists
            rm -f "${REPO_ARCH_DIR}/${pkg_filename}"
          fi
        else
          echo "  -> Package already exists in cache: ${pkg_filename}"
        fi
      done
      
      # --- Step 3: Update repository database ---
      cd "${REPO_ARCH_DIR}"
      
      if ! ls ./*.pkg.tar.zst 1> /dev/null 2>&1; then
        echo "Repository is empty after sync. Clearing any old database files."
        rm -f ${REPO_NAME}.*
        REPO_UPDATED=false
      fi

      if [ "$REPO_UPDATED" = true ]; then
        echo "Repository was updated. Rebuilding database..."
        rm -f ${REPO_NAME}.*
        repo-add "${REPO_NAME}.db.tar.gz" *.pkg.tar.zst
      else
        echo "No changes detected. Using database from cache."
        # Ensure database files exist even if no updates
        if [ ! -f "${REPO_NAME}.db.tar.gz" ] && ls ./*.pkg.tar.zst 1> /dev/null 2>&1; then
          echo "Database missing but packages exist. Rebuilding database..."
          repo-add "${REPO_NAME}.db.tar.gz" *.pkg.tar.zst
        fi
      fi
      
      # --- Step 4: CRITICAL FIX FOR GITLAB PAGES (403 ERROR) ---
      echo "Ensuring database files are compatible with static hosting..."
      if [ -f "${REPO_NAME}.db.tar.gz" ]; then
        rm -f "${REPO_NAME}.db" "${REPO_NAME}.files"
        cp "${REPO_NAME}.db.tar.gz" "${REPO_NAME}.db"
        cp "${REPO_NAME}.files.tar.gz" "${REPO_NAME}.files"
        echo "Database files are correctly formatted."
      else
        echo "No packages in repository. Creating empty placeholder files."
        touch "${REPO_NAME}.db" "${REPO_NAME}.files"
      fi
      
      # --- Step 5: Return to root and create a dummy index.html ---
      cd ../.. # Return to project root ($CI_PROJECT_DIR)
      echo '<html><body><h1>CrystalLinux Repository</h1><a href="x86_64/">x86_64</a></body></html>' > "${REPO_DIR}/index.html"

      # --- Step 6: FINAL DEBUGGING STEP ---
      # This will show us EXACTLY what is being sent to the artifacts uploader.
      echo "-----------------------------------------"
      echo "Final check before artifact upload:"
      echo "Current directory: $(pwd)"
      echo "Listing all files recursively..."
      ls -laR
      echo "-----------------------------------------"

  artifacts:
    paths:
      # This is the directory that GitLab Pages will deploy.
      - public