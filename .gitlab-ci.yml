#
# CI/CD Pipeline for an CrystalLinux Aggregator Repository
# This pipeline fetches, syncs, and publishes a unified pacman repository.
#
image: archlinux:latest

variables:
  REPO_NAME: "crystallinux"
  REPO_DIR: "public" 
  PACKAGE_PROJECT_IDS: "70724583"

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule'
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == 'push'

# --- Cache ---
cache:
  key: "repo-cache-${CI_COMMIT_REF_SLUG}"
  paths:
    - "${REPO_DIR}/"
  policy: pull-push

# --- The combined build and deploy job ---
pages:
  stage: deploy
  
  before_script:
    - pacman -Syu --noconfirm
    - pacman -S --noconfirm curl jq base-devel git
  
  script:
    - set -eo pipefail # Exit on any error
    - REPO_ARCH_DIR="${REPO_DIR}/x86_64"
    - mkdir -p "${REPO_ARCH_DIR}"
    - echo "Repository directory is ${REPO_ARCH_DIR}"
    - echo "Initial contents from cache:"
    - ls -R "${REPO_DIR}"
    
    # --- Step 1: Get a list of ALL expected remote packages ---
    - declare -A remote_packages_map # Use an associative array for efficient lookups
    - echo "Fetching list of all available remote packages..."
    - |
      for project_id in $PACKAGE_PROJECT_IDS; do
        echo "--> Checking project ID: ${project_id}"
        
        PIPELINES_API_URL="https://gitlab.com/api/v4/projects/${project_id}/pipelines?status=success&ref=main&per_page=1"
        PIPELINE_ID=$(curl --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$PIPELINES_API_URL" | jq -r '.[0].id')
        
        if [ "$PIPELINE_ID" = "null" ]; then
          echo "WARNING: No successful pipeline found for project ${project_id}. Skipping."
          continue
        fi
        
        JOBS_API_URL="https://gitlab.com/api/v4/projects/${project_id}/pipelines/${PIPELINE_ID}/jobs?scope[]=success"
        JOB_WITH_ARTIFACTS=$(curl --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$JOBS_API_URL" | jq -r '[.[] | select(.artifacts_file != null)][0].id')
        
        if [ "$JOB_WITH_ARTIFACTS" = "null" ]; then
          echo "WARNING: No job with artifacts found in pipeline ${PIPELINE_ID}. Skipping."
          continue
        fi
        
        # This API endpoint lists files inside the artifact zip without downloading it
        ARTIFACTS_BROWSE_URL="https://gitlab.com/api/v4/projects/${project_id}/jobs/${JOB_WITH_ARTIFACTS}/artifacts"
        mapfile -t pkg_files < <(curl --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$ARTIFACTS_BROWSE_URL" | jq -r '.[] | select(.filename | endswith(".pkg.tar.zst")) | .filename')
        
        for pkg_file in "${pkg_files[@]}"; do
          echo "Found remote package: ${pkg_file}"
          remote_packages_map["${pkg_file}"]="${project_id}/${JOB_WITH_ARTIFACTS}"
        done
      done
    - |
      echo "Total unique remote packages found: ${#remote_packages_map[@]}"
    
    # --- Step 2: Sync local repository with remote list ---
    - REPO_UPDATED=false
    
    # 2a: Remove orphaned packages
    - echo "Checking for orphaned packages in local repository..."
    - |
      for local_pkg_path in "${REPO_ARCH_DIR}"/*.pkg.tar.zst; do
        [ -f "$local_pkg_path" ] || continue # Handle case where no local packages exist
        local_pkg_filename=$(basename "$local_pkg_path")
        if [[ ! -v remote_packages_map["${local_pkg_filename}"] ]]; then
          echo "  -> Removing orphaned package: ${local_pkg_filename}"
          rm "$local_pkg_path"
          REPO_UPDATED=true
        fi
      done
    
    # 2b: Download new or updated packages
    - echo "Checking for new packages to download..."
    - |
      for pkg_filename in "${!remote_packages_map[@]}"; do
        if [ ! -f "${REPO_ARCH_DIR}/${pkg_filename}" ]; then
          echo "  -> Downloading new package: ${pkg_filename}"
          
          # Extract project_id and job_id from our map
          IFS='/' read -r project_id job_id <<< "${remote_packages_map[$pkg_filename]}"
          
          DOWNLOAD_URL="https://gitlab.com/api/v4/projects/${project_id}/jobs/${job_id}/artifacts/${pkg_filename}"
          curl --location --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "${REPO_ARCH_DIR}/${pkg_filename}" "${DOWNLOAD_URL}"
          REPO_UPDATED=true
        fi
      done
      
    # --- Step 3: Update repository database ---
    - cd "${REPO_ARCH_DIR}"
    - |
      # We check for *.pkg.tar.zst files in case the repo is empty after sync.
      if ! ls ./*.pkg.tar.zst 1> /dev/null 2>&1; then
        echo "Repository is empty. Clearing database files."
        rm -f ${REPO_NAME}.*
        REPO_UPDATED=false # Don't try to build a db from nothing
      fi

      if [ "$REPO_UPDATED" = true ]; then
        echo "Repository was updated. Rebuilding database..."
        rm -f ${REPO_NAME}.* # Clean old db files
        repo-add "${REPO_NAME}.db.tar.gz" *.pkg.tar.zst
      else
        echo "No changes detected. Using database from cache."
      fi
      
      # --- Step 4: CRITICAL FIX FOR GITLAB PAGES (403 ERROR) ---
      # This runs every time to guarantee the final artifact is correct.
      echo "Ensuring database files are compatible with static hosting..."
      if [ -f "${REPO_NAME}.db.tar.gz" ]; then
        rm -f "${REPO_NAME}.db" "${REPO_NAME}.files"
        cp "${REPO_NAME}.db.tar.gz" "${REPO_NAME}.db"
        cp "${REPO_NAME}.files.tar.gz" "${REPO_NAME}.files"
        echo "Database files are correctly formatted."
      else
        echo "No packages in repository. Creating empty database files for consistency."
        touch "${REPO_NAME}.db" "${REPO_NAME}.files"
      fi
    - cd ../.. # Return to project root

  artifacts:
    paths:
      # This is the directory that GitLab Pages will deploy.
      - public