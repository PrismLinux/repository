#
# CI/CD Pipeline for an CrystalLinux Aggregator Repository
# This pipeline fetches pre-built packages from other GitLab projects
# and publishes them as a unified pacman repository on GitLab Pages.
#
image: archlinux:latest

variables:
  REPO_NAME: "crystallinux"
  REPO_DIR: "public"
  PACKAGE_PROJECT_IDS: "70724583"

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule'
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == 'push'

# --- Cache ---
# Caches the repository contents to avoid re-downloading packages that haven't changed.
cache:
  key: "repo-cache-${CI_COMMIT_REF_SLUG}"
  paths:
    - "${REPO_DIR}/"
  policy: pull-push

# --- Main Stages ---
stages:
  - update # Stage to sync packages and update the database
  - deploy # Stage to deploy to GitLab Pages

# --- Stage 1: Update Repository ---
# Fetches remote packages, removes orphans, and rebuilds the database if needed.
update_repository:
  stage: update
  
  before_script:
    - pacman -Syu --noconfirm
    - pacman -S --noconfirm curl jq base-devel git
  
  script:
    - set -eo pipefail # Exit on any error
    - REPO_ARCH_DIR="${REPO_DIR}/x86_64"
    - mkdir -p "${REPO_ARCH_DIR}"
    - echo "Repository directory is ${REPO_ARCH_DIR}"
    
    # --- Step 1: Get a list of ALL expected remote packages ---
    - declare -A remote_packages_map # Use an associative array for efficient lookups
    - echo "Fetching list of all available remote packages..."
    - |
      for project_id in $PACKAGE_PROJECT_IDS; do
        echo "--> Checking project ID: ${project_id}"
        
        PIPELINES_API_URL="https://gitlab.com/api/v4/projects/${project_id}/pipelines?status=success&ref=main&per_page=1"
        PIPELINE_ID=$(curl --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$PIPELINES_API_URL" | jq -r '.[0].id')
        
        if [ "$PIPELINE_ID" = "null" ]; then
          echo "WARNING: No successful pipeline found for project ${project_id}. Skipping."
          continue
        fi
        
        JOBS_API_URL="https://gitlab.com/api/v4/projects/${project_id}/jobs?pipeline_id=${PIPELINE_ID}&scope[]=success"
        JOB_WITH_ARTIFACTS=$(curl --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$JOBS_API_URL" | jq -r '[.[] | select(.artifacts_file != null)][0].id')
        
        if [ "$JOB_WITH_ARTIFACTS" = "null" ]; then
          echo "WARNING: No job with artifacts found in pipeline ${PIPELINE_ID}. Skipping."
          continue
        fi
        
        # Get the list of all .pkg.tar.zst files in the artifacts
        ARTIFACTS_BROWSE_URL="https://gitlab.com/api/v4/projects/${project_id}/jobs/${JOB_WITH_ARTIFACTS}/artifacts"
        mapfile -t pkg_files < <(curl --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" "$ARTIFACTS_BROWSE_URL" | jq -r '.[] | select(.filename | endswith(".pkg.tar.zst")) | .filename')
        
        for pkg_file in "${pkg_files[@]}"; do
          echo "Found remote package: ${pkg_file}"
          remote_packages_map["${pkg_file}"]="${project_id}/${JOB_WITH_ARTIFACTS}"
        done
      done
    - |
      echo "Total unique remote packages found: ${#remote_packages_map[@]}"
    
    # --- Step 2: Sync local repository with remote list ---
    - REPO_UPDATED=false
    
    # 2a: Remove orphaned packages
    - echo "Checking for orphaned packages in local repository..."
    - |
      for local_pkg_path in "${REPO_ARCH_DIR}"/*.pkg.tar.zst; do
        [ -f "$local_pkg_path" ] || continue # Handle case where no local packages exist
        local_pkg_filename=$(basename "$local_pkg_path")
        if [[ ! -v remote_packages_map["${local_pkg_filename}"] ]]; then
          echo "  -> Removing orphaned package: ${local_pkg_filename}"
          rm "$local_pkg_path"
          REPO_UPDATED=true
        fi
      done
    
    # 2b: Download new or updated packages
    - echo "Checking for new packages to download..."
    - |
      for pkg_filename in "${!remote_packages_map[@]}"; do
        if [ ! -f "${REPO_ARCH_DIR}/${pkg_filename}" ]; then
          echo "  -> Downloading new package: ${pkg_filename}"
          
          # Extract project_id and job_id from our map
          IFS='/' read -r project_id job_id <<< "${remote_packages_map[$pkg_filename]}"
          
          DOWNLOAD_URL="https://gitlab.com/api/v4/projects/${project_id}/jobs/${job_id}/artifacts/${pkg_filename}"
          curl --location --silent --show-error --header "PRIVATE-TOKEN: $GITLAB_TOKEN" --output "${REPO_ARCH_DIR}/${pkg_filename}" "${DOWNLOAD_URL}"
          REPO_UPDATED=true
        fi
      done
      
    # --- Step 3: Update repository database ---
    - cd "${REPO_ARCH_DIR}"
    - |
      if [ "$REPO_UPDATED" = true ]; then
        echo "Repository was updated. Rebuilding database..."
        # Remove old database files to ensure a clean state
        rm -f ${REPO_NAME}.*
        repo-add "${REPO_NAME}.db.tar.gz" *.pkg.tar.zst
      else
        echo "No changes detected. Skipping database rebuild."
      fi
      
      # --- Step 4: CRITICAL FIX FOR GITLAB PAGES (403 ERROR) ---
      # This must run every time to ensure the artifacts for Pages are correct,
      # regardless of whether the database was rebuilt or restored from cache.
      echo "Ensuring database files are compatible with static hosting..."
      if [ -f "${REPO_NAME}.db.tar.gz" ]; then
        # Remove symlinks and replace them with hard copies
        rm -f "${REPO_NAME}.db" "${REPO_NAME}.files"
        cp "${REPO_NAME}.db.tar.gz" "${REPO_NAME}.db"
        cp "${REPO_NAME}.files.tar.gz" "${REPO_NAME}.files"
        echo "Database files are correctly formatted for deployment."
      else
        echo "No packages in repository. Creating empty database files."
        touch "${REPO_NAME}.db" "${REPO_NAME}.files"
      fi
    - cd ../.. # Return to project root

  artifacts:
    paths:
      - "${REPO_DIR}/" # Make the entire public directory available for the deploy stage
    expire_in: 1 hour

# --- Stage 2: Deploy to GitLab Pages ---
pages:
  stage: deploy
  needs:
    - job: update_repository
      artifacts: true
  script:
    - set -eo pipefail
    - echo "Deploying repository to GitLab Pages..."
    - |
      if [ ! -d "${REPO_DIR}/x86_64" ] || [ -z "$(ls -A "${REPO_DIR}/x86_64")" ]; then
        echo "Repository directory is empty or missing. Nothing to deploy."
      else
        echo "Contents of the repository to be deployed:"
        ls -R "${REPO_DIR}"
        echo "Deployment to GitLab Pages will proceed."
      fi
  artifacts:
    paths:
      - public # GitLab Pages specifically deploys the 'public' directory
    expire_in: 1 week